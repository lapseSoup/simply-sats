use std::sync::Arc;
use std::collections::HashSet;
use std::time::{SystemTime, UNIX_EPOCH};
use serde::{Deserialize, Serialize};
use tokio::sync::Mutex;
use tauri_plugin_sql::{Migration, MigrationKind};
use rand::distributions::Alphanumeric;
use rand::Rng;
use hmac::{Hmac, Mac};
use sha2::Sha256;

type HmacSha256 = Hmac<Sha256>;

mod brc100_signing;
mod crypto;
mod http_server;
mod key_derivation;
mod key_store;
mod rate_limiter;
mod secure_storage;
mod transaction;

use rate_limiter::{
    SharedRateLimitState, RateLimitState,
    check_unlock_rate_limit, record_failed_unlock,
    record_successful_unlock, get_remaining_unlock_attempts,
    load_persisted_state
};

use secure_storage::{
    secure_storage_save, secure_storage_load,
    secure_storage_exists, secure_storage_clear,
    secure_storage_migrate
};

// CSRF/Replay protection constants
const NONCE_EXPIRY_SECS: u64 = 300; // 5 minutes
const MAX_USED_NONCES: usize = 1000; // Prevent memory exhaustion

// Session token TTL: 1 hour — forces periodic rotation even without state-changing ops
const SESSION_TOKEN_TTL_SECS: u64 = 3600;

// Session state for HTTP server authentication
pub struct SessionState {
    pub token: String,
    pub token_created_at: u64,
    pub csrf_secret: String,
    pub used_nonces: HashSet<String>,
    pub nonce_timestamps: Vec<(String, u64)>,
    pub account_id: Option<u32>,
}

impl SessionState {
    pub fn new() -> Self {
        let now = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap_or_default()
            .as_secs();

        // Generate 48-character alphanumeric token using CSPRNG
        // 62 possible chars (a-z, A-Z, 0-9) = ~5.95 bits per char
        // 48 chars = ~286 bits of entropy (exceeds 256-bit security)
        let token: String = rand::thread_rng()
            .sample_iter(&Alphanumeric)
            .take(48)
            .map(char::from)
            .collect();

        // Generate separate CSRF secret for nonce generation
        let csrf_secret: String = rand::thread_rng()
            .sample_iter(&Alphanumeric)
            .take(32)
            .map(char::from)
            .collect();

        Self {
            token,
            token_created_at: now,
            csrf_secret,
            used_nonces: HashSet::new(),
            nonce_timestamps: Vec::new(),
            account_id: None,
        }
    }

    /// Rotate the session token (call after state-changing operations or TTL expiry)
    pub fn rotate_token(&mut self) -> String {
        self.token = rand::thread_rng()
            .sample_iter(&Alphanumeric)
            .take(48)
            .map(char::from)
            .collect();
        self.token_created_at = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap_or_default()
            .as_secs();
        self.token.clone()
    }

    /// Check if the session token has expired
    pub fn is_token_expired(&self) -> bool {
        let now = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap_or_default()
            .as_secs();
        now > self.token_created_at + SESSION_TOKEN_TTL_SECS
    }

    /// Generate a new CSRF nonce, cryptographically bound to csrf_secret via HMAC
    pub fn generate_nonce(&self) -> String {
        let timestamp = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap_or_default()
            .as_secs();

        let random: String = rand::thread_rng()
            .sample_iter(&Alphanumeric)
            .take(16)
            .map(char::from)
            .collect();

        // HMAC-SHA256(csrf_secret, "timestamp_random") binds the nonce to this session
        let payload = format!("{}_{}", timestamp, random);
        let hmac_hex = self.compute_nonce_hmac(&payload);

        format!("{}_{}_{}", timestamp, random, hmac_hex)
    }

    /// Compute HMAC-SHA256 for nonce binding
    fn compute_nonce_hmac(&self, payload: &str) -> String {
        let mut mac = HmacSha256::new_from_slice(self.csrf_secret.as_bytes())
            .expect("HMAC can take key of any size");
        mac.update(payload.as_bytes());
        let result = mac.finalize();
        hex::encode(result.into_bytes())
    }

    /// Validate and consume a nonce (returns true if valid)
    pub fn validate_nonce(&mut self, nonce: &str) -> bool {
        // Clean up expired nonces first
        self.cleanup_expired_nonces();

        // Check if already used
        if self.used_nonces.contains(nonce) {
            return false;
        }

        // Parse: {timestamp}_{random}_{hmac_hex}
        let parts: Vec<&str> = nonce.splitn(3, '_').collect();
        if parts.len() != 3 {
            return false;
        }

        let nonce_time: u64 = match parts[0].parse() {
            Ok(t) => t,
            Err(_) => return false,
        };

        // Verify HMAC — proves this nonce was generated by this session
        let payload = format!("{}_{}", parts[0], parts[1]);
        let expected_hmac = self.compute_nonce_hmac(&payload);
        if parts[2] != expected_hmac {
            return false;
        }

        let now = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap_or_default()
            .as_secs();

        // Check if nonce is expired
        if now > nonce_time + NONCE_EXPIRY_SECS {
            return false;
        }

        // Check if nonce is from the future (clock skew tolerance: 60s)
        if nonce_time > now + 60 {
            return false;
        }

        // Mark as used
        self.used_nonces.insert(nonce.to_string());
        self.nonce_timestamps.push((nonce.to_string(), nonce_time));

        true
    }

    /// Remove expired nonces from memory
    fn cleanup_expired_nonces(&mut self) {
        let now = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap_or_default()
            .as_secs();

        // Remove expired nonces
        self.nonce_timestamps.retain(|(nonce, timestamp)| {
            if now > *timestamp + NONCE_EXPIRY_SECS {
                self.used_nonces.remove(nonce);
                false
            } else {
                true
            }
        });

        // If still too many, remove oldest
        while self.nonce_timestamps.len() > MAX_USED_NONCES {
            if let Some((nonce, _)) = self.nonce_timestamps.first() {
                self.used_nonces.remove(nonce);
            }
            self.nonce_timestamps.remove(0);
        }
    }
}

pub type SharedSessionState = Arc<Mutex<SessionState>>;

/// Get the platform-specific app data directory before Tauri is initialized.
/// Matches Tauri's default path resolution for the app identifier.
/// The `dirs` crate handles platform differences internally:
///   macOS:   ~/Library/Application Support/com.simplysats.wallet
///   Windows: C:\Users\<user>\AppData\Roaming\com.simplysats.wallet
///   Linux:   ~/.local/share/com.simplysats.wallet
fn get_app_data_dir() -> Option<std::path::PathBuf> {
    dirs::data_dir().map(|d| d.join("com.simplysats.wallet"))
}

/// Pre-initialize the database for fresh installs.
///
/// tauri_plugin_sql hangs when migrations contain DML (INSERT/UPDATE/DELETE).
/// For existing databases, migrations are already applied so this is a no-op.
/// For fresh installs, we create the database with the final consolidated schema
/// and mark all migrations as applied, so the plugin skips them entirely.
fn pre_init_database(app_data_dir: &std::path::Path) {
    let db_path = app_data_dir.join("simplysats.db");

    // Only needed for fresh installs — existing DBs already have migrations applied
    if db_path.exists() {
        return;
    }

    // Ensure the directory exists
    if let Err(e) = std::fs::create_dir_all(app_data_dir) {
        log::error!("Failed to create app data dir: {}", e);
        return;
    }

    let conn = match rusqlite::Connection::open(&db_path) {
        Ok(c) => c,
        Err(e) => {
            log::error!("Failed to create database: {}", e);
            return;
        }
    };

    // Execute the consolidated schema
    let schema = include_str!("../migrations/fresh_install_schema.sql");
    if let Err(e) = conn.execute_batch(schema) {
        log::error!("Failed to execute schema: {}", e);
        // Clean up the broken DB file
        let _ = std::fs::remove_file(&db_path);
        return;
    }

    // Mark all 17 migrations as applied with their correct checksums
    // Checksums must match the SQL content exactly or tauri_plugin_sql will re-run them
    let migrations: Vec<(i64, &str, &str)> = vec![
        (1, "Initial database schema", "C00D163C545940AF1CB0E2DC1AABE4A8D66902CFDA8BAAE50DD8D091E4A4D22BD36389CC70B5F95308BB8C29A79C7211"),
        (2, "Derived addresses, address column, and transaction amount", "B74217698A1EA4F9FC2BEBA142D3ACDCFE288917C9BA51A1BEDD173C30A2B904585DF0ECE48EEA4DA6F0F849708F54D7"),
        (3, "Multi-account system", "3E5E2B8934DDE97181F53FCA6EA9AB41BDF2061CFE32370675F142BA76CE03786016AA932319E332521078D96A12B92E"),
        (4, "BSV20 token support", "22204B67014BB2AC66B6BE9CF4CA1E689373FFD6046E63E33E7BB07265148FE8D7211BBF3ED0D997D640F387F2B152B0"),
        (5, "Tagged key derivation and messaging", "E7B9D14B94C622E98E078742ED0E7A3C105D5060EB3D6ACE8026121E7EDDCDDF42D41212020FEC5EC49BA4C1835729DB"),
        (6, "UTXO pending/spent status tracking", "6871DBF8F89509446959E4D1CAE7EFB5F0F01395FACF3991207550AC97AA5A67E2D8F8FD744A5FDEAABF77EA4249AE3E"),
        (7, "Add timestamps to existing tables", "6365EB3E2A63A1270E7A458973E88D5FC6CC127565FFC0337D4C911B475CB7CE7B0384B8D145750683C577D35FEE7345"),
        (8, "Audit log for security monitoring", "0DF94DB4EE8188A37DC15B4859FCA8AF1D6E9AB78ECA503489FAC776F3435F42B4035C2F340B43EF73C02D5D09E66111"),
        (9, "Per-account transaction uniqueness", "C31E62D5BD11868743A22787E75AF75B7FC22D81DCEC20044BEA2657B341F2865E7F56060F0572DBF066191874E26884"),
        (10, "Reset transaction amounts for recalculation", "FC857C579014ED6348868FBCD45CD61B7EE6381FE4DFA0E75DB42BF737DEFF6BAEA906C0AFFB4F1026135F408F2C59B7"),
        (11, "Reset transaction amounts v2 (API fallback)", "091FFB058C9D7CC3C3017E12E680785572255990136F597C67ED018D49260864D13CA09301A2DE1C458F9A887BB0009E"),
        (12, "Clean up cross-account data contamination", "2E64BE0485EE42B15E900B7DF79FF2A2873E525402C903311E6D2AD35F92DB9EE293248131A67B93D053E53C8C75DA56"),
        (13, "Fix transaction_labels foreign key constraint", "694B93F5E6AAB0489222653FF1C06CAECC6454FB9F2032FC2C220302C2144D051F6EC71C44F14C9612A8D9EAA19F08DF"),
        (14, "Add lock_block column to locks", "C44274FCEBDD31E866567D3E9660557B61CE73EFA34824B608CF56C0E3521D33EB3E05A21804EB92C1B3BE7B98EAB8D1"),
        (15, "Ordinal content cache table", "EC58F70A6A31995F53F341C063C363393D5EE4FD8317D45189D4117248CF7D9C7CDE7AD4BD175B57D9026A0EEF7CBC23"),
        (16, "Derived address account scoping", "98C5F5AC4957A3456EC54191A1217DC3AE5C7A84CA2A9DF5D06BF064E431C76661E9C76B51AA2A484BB6050882376AA6"),
        (17, "Unique index on locks utxo_id", "E6B4E1322FB95571CCB99D425494F23DD9851735057F6FEE64A358D1F1FC5DE15B4F62950F9B3E7C3867352B772EF71E"),
        (18, "Add account_id to transaction_labels", "D3284BCD78C6CDB5026836822F7B69BB2119CB9D94847362319C45F3DAFFC1C6DFB26995CF74B4F82C53A25652BF5F60"),
    ];

    for (version, description, checksum_hex) in migrations {
        let checksum = hex_to_bytes(checksum_hex);
        if let Err(e) = conn.execute(
            "INSERT INTO _sqlx_migrations (version, description, success, checksum, execution_time) VALUES (?1, ?2, 1, ?3, 0)",
            rusqlite::params![version, description, checksum],
        ) {
            log::error!("Failed to insert migration {}: {}", version, e);
        }
    }
}

/// Convert hex string to bytes for migration checksums
fn hex_to_bytes(hex: &str) -> Vec<u8> {
    (0..hex.len())
        .step_by(2)
        .map(|i| u8::from_str_radix(&hex[i..i + 2], 16).unwrap_or(0))
        .collect()
}

// Database migrations
fn include_migrations() -> Vec<Migration> {
    vec![
        Migration {
            version: 1,
            description: "Initial database schema",
            sql: include_str!("../migrations/001_initial.sql"),
            kind: MigrationKind::Up,
        },
        Migration {
            version: 2,
            description: "Derived addresses, address column, and transaction amount",
            sql: include_str!("../migrations/002_consolidated.sql"),
            kind: MigrationKind::Up,
        },
        Migration {
            version: 3,
            description: "Multi-account system",
            sql: include_str!("../migrations/003_accounts.sql"),
            kind: MigrationKind::Up,
        },
        Migration {
            version: 4,
            description: "BSV20 token support",
            sql: include_str!("../migrations/004_tokens.sql"),
            kind: MigrationKind::Up,
        },
        Migration {
            version: 5,
            description: "Tagged key derivation and messaging",
            sql: include_str!("../migrations/005_tagged_keys.sql"),
            kind: MigrationKind::Up,
        },
        Migration {
            version: 6,
            description: "UTXO pending/spent status tracking",
            sql: include_str!("../migrations/006_utxo_pending_status.sql"),
            kind: MigrationKind::Up,
        },
        Migration {
            version: 7,
            description: "Add timestamps to existing tables",
            sql: include_str!("../migrations/007_add_timestamps.sql"),
            kind: MigrationKind::Up,
        },
        Migration {
            version: 8,
            description: "Audit log for security monitoring",
            sql: include_str!("../migrations/008_audit_log.sql"),
            kind: MigrationKind::Up,
        },
        Migration {
            version: 9,
            description: "Per-account transaction uniqueness",
            sql: include_str!("../migrations/009_tx_per_account.sql"),
            kind: MigrationKind::Up,
        },
        Migration {
            version: 10,
            description: "Reset transaction amounts for recalculation",
            sql: include_str!("../migrations/010_reset_tx_amounts.sql"),
            kind: MigrationKind::Up,
        },
        Migration {
            version: 11,
            description: "Reset transaction amounts v2 (API fallback)",
            sql: include_str!("../migrations/011_reset_tx_amounts_v2.sql"),
            kind: MigrationKind::Up,
        },
        Migration {
            version: 12,
            description: "Clean up cross-account data contamination",
            sql: include_str!("../migrations/012_cleanup_cross_account.sql"),
            kind: MigrationKind::Up,
        },
        Migration {
            version: 13,
            description: "Fix transaction_labels foreign key constraint",
            sql: include_str!("../migrations/013_fix_transaction_labels.sql"),
            kind: MigrationKind::Up,
        },
        Migration {
            version: 14,
            description: "Add lock_block column to locks",
            sql: include_str!("../migrations/014_add_lock_block.sql"),
            kind: MigrationKind::Up,
        },
        Migration {
            version: 15,
            description: "Ordinal content cache table",
            sql: include_str!("../migrations/015_ordinal_cache.sql"),
            kind: MigrationKind::Up,
        },
        Migration {
            version: 16,
            description: "Derived address account scoping",
            sql: include_str!("../migrations/016_derived_address_account.sql"),
            kind: MigrationKind::Up,
        },
        Migration {
            version: 17,
            description: "Unique index on locks utxo_id",
            sql: include_str!("../migrations/017_lock_utxo_unique.sql"),
            kind: MigrationKind::Up,
        },
        Migration {
            version: 18,
            description: "Add account_id to transaction_labels",
            sql: include_str!("../migrations/018_transaction_labels_account.sql"),
            kind: MigrationKind::Up,
        },
    ]
}

// Shared state for BRC-100 requests
#[derive(Default)]
pub struct BRC100State {
    pub pending_responses: std::collections::HashMap<String, tokio::sync::oneshot::Sender<serde_json::Value>>,
}

pub type SharedBRC100State = Arc<Mutex<BRC100State>>;

#[derive(Clone, Serialize, Deserialize, Debug)]
pub struct BRC100Request {
    pub id: String,
    pub method: String,
    pub params: serde_json::Value,
    pub origin: Option<String>,
}

#[derive(Clone, Serialize, Deserialize, Debug)]
pub struct BRC100Response {
    pub id: String,
    pub result: Option<serde_json::Value>,
    pub error: Option<BRC100Error>,
}

#[derive(Clone, Serialize, Deserialize, Debug)]
pub struct BRC100Error {
    pub code: i32,
    pub message: String,
}

// Command to respond to a BRC-100 request from the frontend
#[tauri::command]
async fn respond_to_brc100(
    state: tauri::State<'_, SharedBRC100State>,
    request_id: String,
    response: serde_json::Value,
) -> Result<(), String> {
    let mut state = state.lock().await;
    if let Some(sender) = state.pending_responses.remove(&request_id) {
        sender.send(response).map_err(|_| "Failed to send response")?;
    }
    Ok(())
}

/// Returns the session token for BRC-100 HTTP API authentication.
///
/// SECURITY NOTE: This token is necessarily accessible from frontend JS
/// because the SDK needs it for HTTP requests to the BRC-100 server.
/// An XSS in the webview would grant full API access. This is an accepted
/// trade-off — the CSP and Tauri's webview isolation mitigate the risk.
#[tauri::command]
async fn get_session_token(
    session_state: tauri::State<'_, SharedSessionState>,
) -> Result<String, String> {
    let session = session_state.lock().await;
    Ok(session.token.clone())
}

// Command to rotate session for a specific account (call on account switch)
// Rotates token, clears all nonces, sets account_id
#[tauri::command]
async fn rotate_session_for_account(
    session_state: tauri::State<'_, SharedSessionState>,
    account_id: u32,
) -> Result<String, String> {
    let mut session = session_state.lock().await;
    let new_token = session.rotate_token();
    session.used_nonces.clear();
    session.nonce_timestamps.clear();
    session.account_id = Some(account_id);
    log::info!("Session rotated for account {}", account_id);
    Ok(new_token)
}

// Command to generate a CSRF nonce for state-changing operations
// Rate-limited: rejects if outstanding (unexpired) nonces exceed 80% of pool capacity
#[tauri::command]
async fn generate_csrf_nonce(
    session_state: tauri::State<'_, SharedSessionState>,
) -> Result<String, String> {
    let mut session = session_state.lock().await;
    // Clean up expired nonces before checking capacity
    let now = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .unwrap_or_default()
        .as_secs();
    let expired: Vec<String> = session.nonce_timestamps.iter()
        .filter(|(_, ts)| now > *ts + NONCE_EXPIRY_SECS)
        .map(|(n, _)| n.clone())
        .collect();
    for nonce in &expired {
        session.used_nonces.remove(nonce);
    }
    session.nonce_timestamps.retain(|(_, ts)| now <= *ts + NONCE_EXPIRY_SECS);
    if session.nonce_timestamps.len() >= MAX_USED_NONCES * 4 / 5 {
        return Err("Too many outstanding nonces — try again later".into());
    }
    Ok(session.generate_nonce())
}

#[cfg_attr(mobile, tauri::mobile_entry_point)]
pub fn run() {
    // Initialize structured logging (RUST_LOG env var controls level, default: info)
    env_logger::Builder::from_env(env_logger::Env::default().default_filter_or("info"))
        .init();

    // Pre-initialize database for fresh installs BEFORE Tauri builder runs.
    // Must happen before tauri_plugin_sql plugin init, which runs migrations.
    // Uses platform-specific app data directory since Tauri isn't initialized yet.
    if let Some(app_data_dir) = get_app_data_dir() {
        pre_init_database(&app_data_dir);
    }

    let brc100_state: SharedBRC100State = Arc::new(Mutex::new(BRC100State::default()));
    let brc100_state_for_server = brc100_state.clone();

    // Generate session token for HTTP server authentication
    let session_state: SharedSessionState = Arc::new(Mutex::new(SessionState::new()));
    let session_state_for_server = session_state.clone();

    // Key store — holds WIFs in Rust-only memory (never exposed to JS)
    let key_store: key_store::SharedKeyStore = Arc::new(Mutex::new(key_store::KeyStoreInner::new()));

    // Rate limiter state — initialized empty, loaded from disk in setup()
    let rate_limit_state: SharedRateLimitState = Arc::new(Mutex::new(RateLimitState::new()));
    let rate_limit_state_for_setup = rate_limit_state.clone();

    tauri::Builder::default()
        .plugin(tauri_plugin_opener::init())
        .plugin(tauri_plugin_deep_link::init())
        .plugin(tauri_plugin_dialog::init())
        .plugin(tauri_plugin_fs::init())
        .plugin(tauri_plugin_store::Builder::new().build())
        .plugin(tauri_plugin_sql::Builder::new()
            .add_migrations("sqlite:simplysats.db", include_migrations())
            .build())
        .manage(brc100_state)
        .manage(session_state)
        .manage(rate_limit_state)
        .manage(key_store)
        .invoke_handler(tauri::generate_handler![
            respond_to_brc100,
            get_session_token,
            generate_csrf_nonce,
            rotate_session_for_account,
            check_unlock_rate_limit,
            record_failed_unlock,
            record_successful_unlock,
            get_remaining_unlock_attempts,
            secure_storage_save,
            secure_storage_load,
            secure_storage_exists,
            secure_storage_clear,
            secure_storage_migrate,
            crypto::encrypt_data,
            crypto::decrypt_data,
            key_derivation::derive_wallet_keys,
            key_derivation::derive_wallet_keys_for_account,
            key_derivation::validate_mnemonic,
            key_derivation::generate_mnemonic,
            key_derivation::keys_from_wif,
            transaction::build_p2pkh_tx,
            transaction::build_multi_key_p2pkh_tx,
            transaction::build_consolidation_tx,
            brc100_signing::sign_message,
            brc100_signing::sign_data,
            brc100_signing::verify_signature,
            brc100_signing::verify_data_signature,
            brc100_signing::encrypt_ecies,
            brc100_signing::decrypt_ecies,
            key_store::store_keys,
            key_store::store_keys_direct,
            key_store::clear_keys,
            key_store::get_public_keys,
            key_store::has_keys,
            key_store::get_mnemonic,
            key_store::get_mnemonic_once,
            key_store::sign_message_from_store,
            key_store::sign_data_from_store,
            key_store::encrypt_ecies_from_store,
            key_store::decrypt_ecies_from_store,
            key_store::build_p2pkh_tx_from_store,
            key_store::build_multi_key_p2pkh_tx_from_store,
            key_store::build_consolidation_tx_from_store,
            key_store::get_wif_for_operation
        ])
        .setup(move |app| {
            let app_handle = app.handle().clone();
            let brc100_state = brc100_state_for_server;
            let session_state = session_state_for_server;

            // Load persisted rate limit state from disk
            let persisted = load_persisted_state(&app_handle);
            let rate_limit_for_load = rate_limit_state_for_setup.clone();
            tauri::async_runtime::block_on(async move {
                let mut state = rate_limit_for_load.lock().await;
                *state = persisted;
            });

            // Start HTTP server in background
            std::thread::spawn(move || {
                let rt = tokio::runtime::Runtime::new().unwrap();
                rt.block_on(async {
                    if let Err(e) = http_server::start_server(app_handle, brc100_state, session_state).await {
                        log::error!("HTTP server error: {}", e);
                    }
                });
            });

            Ok(())
        })
        .run(tauri::generate_context!())
        .expect("error while running tauri application");
}
